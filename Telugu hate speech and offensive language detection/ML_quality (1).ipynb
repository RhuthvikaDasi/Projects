{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('badwords.csv')\n",
        "\n",
        "# Calculate the percentage of hate speech and offensive language\n",
        "total = len(df)\n",
        "hate_speech = len(df[df['class']==0])\n",
        "offensive_language = len(df[df['class']==1])\n",
        "neither = len(df[df['class']==2])\n",
        "hate_speech_percent = (hate_speech / total) * 100\n",
        "offensive_language_percent = (offensive_language / total) * 100\n",
        "neither_percent = (neither / total) * 100\n",
        "\n",
        "# Print the results\n",
        "print(f\"Hate Speech: {hate_speech_percent:.2f}%\")\n",
        "print(f\"Offensive Language: {offensive_language_percent:.2f}%\")\n",
        "print(f\"Neither: {neither_percent:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df-y7KbsnFLz",
        "outputId": "3d2fc462-ddc7-4973-cf38-cfb549b471a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate Speech: 7.07%\n",
            "Offensive Language: 77.12%\n",
            "Neither: 15.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('badwords_sheet.csv')\n",
        "\n",
        "# Define the data quality rules\n",
        "rules = {\n",
        "    'count': 'numeric',\n",
        "    'hate_speech': 'numeric',\n",
        "    'offensive_language': 'numeric',\n",
        "    'neither': 'numeric',\n",
        "    'class': ['0', '1', '2'],\n",
        "    'tweet': 'text'\n",
        "}\n",
        "\n",
        "# Initialize error count\n",
        "error_count = 0\n",
        "total_count = 0\n",
        "\n",
        "# Apply the data quality rules to the dataset\n",
        "for column, rule in rules.items():\n",
        "    if rule == 'numeric':\n",
        "        errors = df[~df[column].apply(lambda x: str(x).isdigit())]\n",
        "    elif rule == 'text':\n",
        "        errors = df[df[column].apply(lambda x: type(x) != str)]\n",
        "    else:\n",
        "        errors = df[~df[column].isin(rule)]\n",
        "    error_count += len(errors)\n",
        "    total_count += len(df)\n",
        "    if not errors.empty:\n",
        "        print(f\"Found {len(errors)} errors in column '{column}'\")\n",
        "\n",
        "# Calculate quality percentage\n",
        "quality_percentage = (1 - error_count / total_count) * 100\n",
        "print(f\"Data quality percentage: {quality_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXETbXGFqRT9",
        "outputId": "9cb1d617-090e-4a29-cfbb-1e34db128cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1499 errors in column 'class'\n",
            "Data quality percentage: 83.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('badwords1.csv')\n",
        "\n",
        "# Define the data quality rules\n",
        "rules = {\n",
        "    'count': 'numeric',\n",
        "    'hate_speech': 'numeric',\n",
        "    'offensive_language': 'numeric',\n",
        "    'neither': 'numeric',\n",
        "    'class': ['0', '1', '2'],\n",
        "    'tweet': 'text'\n",
        "}\n",
        "\n",
        "# Initialize error count\n",
        "error_count = 0\n",
        "total_count = 0\n",
        "\n",
        "# Apply the data quality rules to the dataset\n",
        "for column, rule in rules.items():\n",
        "    if rule == 'numeric':\n",
        "        errors = df[~df[column].apply(lambda x: str(x).isdigit())]\n",
        "    elif rule == 'text':\n",
        "        errors = df[df[column].apply(lambda x: type(x) != str)]\n",
        "    else:\n",
        "        errors = df[~df[column].isin(rule)]\n",
        "    error_count += len(errors)\n",
        "    total_count += len(df)\n",
        "    if not errors.empty:\n",
        "        print(f\"Found {len(errors)} errors in column '{column}'\")\n",
        "\n",
        "# Calculate quality percentage\n",
        "quality_percentage = (1 - error_count / total_count) * 100\n",
        "print(f\"Data quality percentage: {quality_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dACH0Bzo8KUd",
        "outputId": "a6644a79-57dd-42b8-a3d9-11322c801500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1499 errors in column 'class'\n",
            "Data quality percentage: 83.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('badwords1.csv')\n",
        "\n",
        "# Perform data validation\n",
        "# Check for missing values\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Check for outliers\n",
        "outliers = dataset[dataset['count'] > 3 * dataset['count'].std()]\n",
        "print(\"Outliers in 'count' column:\\n\", outliers)\n",
        "\n",
        "# Perform statistical analysis\n",
        "# Calculate mean and standard deviation\n",
        "mean = dataset['hate_speech'].mean()\n",
        "std_dev = dataset['hate_speech'].std()\n",
        "\n",
        "# Check for abnormal values\n",
        "abnormal_values = dataset[dataset['hate_speech'] > mean + 3 * std_dev]\n",
        "print(\"Abnormal values in 'hate_speech' column:\\n\", abnormal_values)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUQg0XgB3GiJ",
        "outputId": "d1433f31-1711-4877-b037-25006ee62deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " Unnamed: 0            0\n",
            "count                 0\n",
            "hate_speech           0\n",
            "offensive_language    0\n",
            "neither               0\n",
            "class                 0\n",
            "tweet                 0\n",
            "dtype: int64\n",
            "Outliers in 'count' column:\n",
            "      Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0             0      3            0                   0        3      2   \n",
            "1             1      3            0                   0        3      2   \n",
            "2             2      3            0                   0        3      2   \n",
            "3             3      3            0                   0        1      2   \n",
            "4             4      3            0                   0        6      2   \n",
            "...         ...    ...          ...                 ...      ...    ...   \n",
            "1494       1525      3            0                   0        3      2   \n",
            "1495       1526      3            0                   0        3      2   \n",
            "1496       1527      3            0                   0        3      2   \n",
            "1497       1528      3            0                   0        3      2   \n",
            "1498       1529      3            0                   0        3      2   \n",
            "\n",
            "                                                  tweet  \n",
            "0                       @nameisnani nuvv chala bagunnav  \n",
            "1         Handsome hunk, vacchu neevu naa naeta ayyaava  \n",
            "2        melu..... ilanti rachanalu chala avasaram ....  \n",
            "3       Vera level BGM .. trailer aneka·πÅ kikku icchindi  \n",
            "4              meeru emi chestunnaru?!!!! aa talli !!!!  \n",
            "...                                                 ...  \n",
            "1494              Alaram mogutu untadi... Kani legamu..  \n",
            "1495  Maa oori bhasha ante aa maatram untaadi   leir...  \n",
            "1496  Bro.. Indaake virupaksha movie chusi, dhaduchu...  \n",
            "1497  Yedavalaku Assalu taste ledhu.... Em padoite a...  \n",
            "1498  tenkasi jilla nadar community tarapuna subhaka...  \n",
            "\n",
            "[1499 rows x 7 columns]\n",
            "Abnormal values in 'hate_speech' column:\n",
            " Empty DataFrame\n",
            "Columns: [Unnamed: 0, count, hate_speech, offensive_language, neither, class, tweet]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}